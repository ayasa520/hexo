---
title: 数据科学基础(八) 多维
categories: 'NJU 笔记'
tag: ['概率论','数学']
date: 2020-12-27
---


{% note blue ' fas fa-rocket' modern %}
📚 文档目录
<a href="/2020/12/27/数据科学基础/数据科学基础_01">随机事件及其概率</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_02">随机变量及其分布</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_03">期望和方差</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_04">大数定律与中心极限定理</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_05">数理统计的基本概念</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_06">参数估计</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_07">假设检验</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_08">多维</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_09">回归分析和方差分析</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_10">降维</a>
{% endnote %}


## 8.1 多维概率分布

**分布函数:** $F(x,y) = P\\{X \leq x,Y \leq y\\}$

**密度函数:** $\displaystyle f(x,y) = \frac{\partial F}{\partial x\partial y}$

**边缘分布**: 设 $(X, Y)$ 为二维随机变量,称一维随机变量 $X$ 或 $Y$ 的概率分布为二维随机变量 $(X, Y)$ 关于 $X$ 或 $Y$ 对应的边缘分布; 分别记作: $F_{X}(x), F_{Y}(y)_{}$

**二维离散型边缘分布率**:
设二维随机变量 $(X, Y)$ 的分布律为 $p_{i j},$ 那么对千随机变量 $X, Y$ 其各自的分布律对于固定的 $i, j=1,2, \cdots,$ 满足
$$
P\left\{X=x_{i}\right\}=\sum_{j} p_{i j}=p_{i}
$$
则称 $p_{i} .$ 为随机变量 $(X, Y)$ 的边缘分布律。

**二维连续型的边缘概率密度:**
设二维随机变量$(X,Y)$的概率密度为$f(x,y)$, 由于
$$
F_{X}(x)=\int_{-\infty}^{x} \int_{-\infty}^{\infty} f(x, y) d y d x, F_{Y}(y)=\int_{-\infty}^{y} \int_{-\infty}^{\infty} f(x, y) d x d y
$$

则
$$
\begin{array}{l}
f_{X}(x)=\int_{-\infty}^{+\infty} f(x, y) d y \\
f_{Y}(y)=\int_{-\infty}^{+\infty} f(x, y) d x
\end{array}
$$

**二维离散随机变量的条件概率:**
设 $(X, Y)$ 是二维离散型随机变量，其分布律为 $P\\{X=x_{i}, Y=y_{j}\\}=p_{i j},$ 其边缘概率分别为 $p_{i}, p_{\cdot j} .$ 则条件概率定义为
$$
\displaystyle\begin{array}{l}
P\left\{X=x_{i} \mid Y=y_{j}\right\}=\frac{P\left\{X=x_{i}, Y=y_{j}\right\}}{P\left\{Y=y_{j}\right\}}=\frac{p_{i j}}{p_{\cdot j}} \\
P\left\{Y=y_{j} \mid \mathrm{X}=x_{j}\right\}=\frac{P\left\{X=x_{i}, Y=y_{j}\right\}}{P\left\{X=x_{i}\right\}}=\frac{p_{i j}}{p_{i}}
\end{array}
$$

**独立性:** 联合概率 = 边缘概率相乘
$$
\begin{aligned}
&F(x,y)=F_X(x) \cdot F_Y(y),\\
&P\{X \leq x, Y \leq y\}=P\{X \leq x\} P\{Y \leq y\}
\end{aligned}
$$
几乎处处成立, 则随机变量$X,Y$是相互独立的

也可以用 $f(x,y)$ 可分离判断.



## 8.2 $\chi^2$ 独立性检验

假设两个随机变量 $X,Y$, 给定显著性水平 $\alpha$ , 检验非参数假设:

$H_0: X,Y$ 相互独立, $H_1: X,Y$ 不相互独立

<img src="https://unpkg.zhimg.com/rikka-os@1.0.3/img/image-20210502234756426.webp" alt="image-20210502234756426" style="zoom:80%;" />

若随机变量 $X,Y$ 独立, 则联合概率  = 边缘概率$\times$边缘概率. 即, 若原假设 $H_0$ 成立, 那么实际联合概率(相对应的经验频数)和理论联合概率,即边缘概率之积(相对应的理论频数)不会相差很大. 构造下方的统计量.
$$
\chi^{2}=\sum \frac{\left(E_{i j}-T_{i j}\right)^{2}}{T_{i j}}
$$

其中经验频数 $$E_{ij}=n_{ij}$$, 理论频数$$T_{ij}=n\cdot \frac{n_i}{n} \cdot \frac{n_j}{n}$$, 当 $$n$$ 充分大时, $$\chi^2$$ 近似服从 $$\chi^2$$ 分布:

$$
\chi^{2} \sim \chi^{2}((r-1)(c-1)), r 为行数, c 为列数
$$
若 $H_0$ 假设成立, 则经验频数和理论频数相差不应该太大, 所以拒绝域为:
$$
\chi^{2} \geq \chi_{\alpha}^{2}((r-1)(c-1))
$$


