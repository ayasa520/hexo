---
title:  数据科学基础(三) 期望和方差
categories: 'NJU 笔记'
tag: ['概率论','数学']
date: 2020-12-27
---
 

{% note blue ' fas fa-rocket' modern %}
📚 文档目录
<a href="/2020/12/27/数据科学基础/数据科学基础_01">随机事件及其概率</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_02">随机变量及其分布</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_03">期望和方差</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_04">大数定律与中心极限定理</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_05">数理统计的基本概念</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_06">参数估计</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_07">假设检验</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_08">多维</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_09">回归分析和方差分析</a>
<a href="/2020/12/27/数据科学基础/数据科学基础_10">降维</a>
{% endnote %}



## 3.1 数学期望

### 3.1.1 离散型数据的数学期望 

+ $P(X=x_k)= p_k,$ 若 $\sum^\infty_{k=1}x_kp_k$ 绝对收敛,则 $E(X)=\sum^\infty_{k=1}x_kp_k$.
  注意:数学期望不一定均存在.

### 3.1.2 连续型数据的数学期望 

+ $X$ 的密度函数为 $f(x),\int_{-\infty}^{\infty}xf(x)dx$ 绝对收敛,则$Ex = \int_{-\infty}^{\infty}xf(x)dx$

### 3.1.3 随机变量函数的期望

$Y=g(X)$

+ 离散 $E(X)=\sum x_i p_i,Y=g(X)$则$E(Y)=\sum g(x_i)p_i$

### 3.1.4 期望的性质

+ $EC=C$
+ $E(C_1X+C_2)=C_1EX+C_2$
+ 若$X,Y$ 独立,则 $E(XY)=E(X)E(Y)$
+ $E(X \pm Y)=EX \pm EY$           

## 3.2 方差

### 3.2.1 方差的定义

+ $DX = E((X-EX)^2)$
+ 离散型: $DX=\sum(X_k-EK)^2p_k$
+ 连续型: $DX=\sum_{-\infty}^{+\infty}(x-EX)^2f(x)dx$

但是一般用 $DX=E(X^2)-(EX)^2$ 计算.

### 3.2.2 方差的性质

+ $DC=0$
+ $D(C_1X+C_2) = C_1^2DX$
+ 若$X,Y$ **独立** 则$D(X \pm Y) = D(X)+D(Y)$

## 3.3 常见分布的期望和方差

### 3.3.1 常见离散型的期望与方差

#### 1. 0-1分布

+ $EX = p$
+ $DX=E(X^2)-(EX)^2=p-p^2=p(1-p)$

#### 2. 二项分布

+ 期望
  设
  $$
  X_i=\begin{cases}
    1,\text{the }\,\text{i-th}\,\text{ is}\,\text{ failure }\\
    0, \text{the }\,\text{i-th}\,\text{ is}\,\text{ success}
  \end{cases},
  $$
  则$E(X_i)=1 \times p+0 \times (1-p)=p,E(X)=E(\sum_{i=1}^nXi)=np$

+ 方差
  $DX=D(\sum_{i=1}^nXi)=np(1-p)$ 

#### 3. 几何分布

$P\\{X=k\\}= (1-p)^{k-1}p$
$EX=\sum_{k=1}^nk(1-p)^{k-1}p=\frac{1}{p}$运用级数求和
$DX=\sum_{k=1}^nk^2(1-p)^{k-1}p=\frac{1-p}{p^2}$,借助$\sum_{k=1}^\infty k^2X^{k-1}=\sum_{k=1}^\infty k \cdot kX^{k-1}=(\sum_{k=1}^\infty  kX^k)'=(X\sum_{k=1}^\infty  kX^{k-1})'=(\frac{X}{(1-X)^2})'=\frac{1-x}{x^2}$

#### 4. 泊松分布

$P\\{X=k\\}=\frac{\lambda^k}{k!}e^{- \lambda},k=0,1,2,3,...,\lambda>0,X$~$P(\lambda)$

+ $EX=\sum_{k=0}^\infty k\frac{\lambda^k}{k!}e^{- \lambda}=\sum_{k=1}^\infty \frac{\lambda^k}{(k-1)!}e^{- \lambda}=\lambda \sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!}e^{- \lambda}=\lambda \times 1=\lambda$(可以用概率和为1).
+ 方差 
  $$
  \begin{aligned}E(X^2)&=\sum_{k=0}^\infty k^2\frac{\lambda^k}{k!}e^{- \lambda}\\&=\sum_{k=1}^\infty k\frac{\lambda^k}{(k-1)!}e^{- \lambda}\\
  &=\lambda\sum_{k=1}^\infty \frac{\lambda^{k-1}}{(k-1)!}e^{- \lambda}+\sum_{k=1}^\infty (k-1)\frac{\lambda^k}{(k-1)!}e^{- \lambda}\\&=\lambda+\sum_{k=2}^\infty \frac{\lambda^k}{(k-2)!}e^{- \lambda}\\&=\lambda+\lambda^{2}\sum_{k=2}^\infty \frac{\lambda^{k-2}}{(k-2)!}e^{- \lambda}\\&=\lambda+\lambda^2\\\end{aligned}
  $$
  则
  $$
  \begin{aligned}DX=\lambda+\lambda^2-\lambda^2=\lambda\end{aligned}$$

### 3.3.2 常见连续型的期望与方差

#### 1. 均匀分布

+ $f(x)=\begin{cases}
  \frac{1}{b-a},a \leq x \leq b \\
  0, else\\
  \end{cases}$

+ $\begin{aligned}
  EX=\int_a^bx\frac{1}{b-a}dx=\frac{a+b}{2}\end{aligned}$
+ $\begin{aligned}E(X^2)=\int_a^bx^{2}\frac{1}{b-a}dx=\frac{b^2+ab+a^2}{3}\end{aligned}$


  $\begin{aligned}DX=\frac{b^2+ab+a^2}{3}-(\frac{a+b}{2})^2=\frac{(b-a)^2}{12}\end{aligned}$

#### 2. 指数分布

+ $f(x) = \begin{cases}
  \frac{1}{ \theta} e^{-\frac{1}{ \theta} x},x \gt 0\\
   0, x \leq 0\\
  \end{cases}$


+ 期望
  $\begin{aligned}EX&=\int_{0}^{\infty}x\cdot \frac{1}{ \theta} e^{-\frac{1}{ \theta} x}dx&=\theta\end{aligned}$

+ 方差
  $\begin{aligned}D(X^2)=\int_{0}^{\infty}x^{2}\cdot \frac{1}{ \theta} e^{-\frac{1}{ \theta} x}dx = \theta^{2}\end{aligned}$

#### 3. 正态分布

+ $E(X)=\mu,D(X)=\sigma^2$
  证明:
     $Z=\frac{X-\mu}{\sigma}$,则 $Z\sim N(0,1)$

     $E(Z)=\displaystyle\int_{-\infty}^{+\infty}x\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx=0$

     $D(Z)=E(X^2)-(EX)^2=1$   

     然后$E(X)=E(\sigma Z+\mu)=\mu,D(X)=D(\sigma Z+\mu)=\sigma^2$

## 3.4. 协方差和相关系数

### 3.4.1. 协方差

当随机变量$X,Y$ 独立时, $D(X+Y) = D(X)+D(Y)$.

当不独立的时候,  $D(X+Y) = E((X+Y)^2)-(E(X+Y))^2$, 化简可以得到定理:

$$
D(X \pm Y) = D(X)+D(Y)\pm 2E((X-EX)(Y-EY)
$$

其中**协方差** $Cov(X,Y)=E((X-EX)(Y-EY))$

**推论**: $E(XY)-E(X)E(Y)=Cov(X,Y)$

$Cov(X+Y,Z)=Cov(X,Z)+Cov(Y,Z)$

### 3.4.2. 相关系数

$$\displaystyle \rho _{X,Y}=\frac{Cov(X,Y)}{\sqrt{D(X)D(Y)}}$$

### 3.5 中心距和原点矩

+ $k$ 阶原点矩: $EX^k$. 例:$EX$ 一阶原点矩.
+ $k$ 阶中心距: $E((X-EK)^k)$. 例: 一阶中心距:0; 二阶中心矩:$E((X-EX)^2)$,即方差.
